# @package _global_

# -- this run_location reads data from the /tmp folder and prepares it if it is missing
#    this is useful if we need to read data constantly from the disk
#    |
#    |
#    |

dsettings:
  trainer:
    cuda: NULL  # auto-detect cuda, some nodes may be configured incorrectly
  storage:
    logs_dir: 'logs'
    data_root: '/tmp/${oc.env:USER}/datasets'
  dataset:
    prepare: TRUE
    try_in_memory: TRUE
  launcher:
    partition: stampede
    array_parallelism: 16
    exclude: "cluster92,cluster94,cluster96"

datamodule:
  gpu_augment: FALSE
  prepare_data_per_node: TRUE
  dataloader:
    num_workers: 16
    pin_memory: ${dsettings.trainer.cuda}  # uses more memory, but faster!
    batch_size: ${settings.dataset.batch_size}

hydra:
  job:
    name: 'disent'
  run:
    dir: '${dsettings.storage.logs_dir}/hydra_run/${now:%Y-%m-%d_%H-%M-%S}_${hydra.job.name}'
  sweep:
    dir: '${dsettings.storage.logs_dir}/hydra_sweep/${now:%Y-%m-%d_%H-%M-%S}_${hydra.job.name}'
    subdir: '${hydra.job.id}' # hydra.job.id is not available for dir
